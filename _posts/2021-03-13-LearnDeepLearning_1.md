---
layout: post
title:  "프레임워크 없이 딥러닝 구현해보기 1일차"
date:   2021-03-13 21:39:13 +0800
categories: 1인_1프로젝트
tags: 딥러닝 1인1프로젝트
comments: true
---

밑바닥부터 시작하는 딥러닝(사이토 고키)라는 책을 읽으면서 딥러닝을 다시 공부해보고 있습니다. 



### 오늘의 배운 것

퍼셉트론은 다수의 신호를 입력으로 받아 하나의 신호를 출력한다. 가중치와 편향으로 구성된다.

단층 퍼셉트론으로는 XOR 게이트를 표현할 수 없다. 층을 더 쌓은 다층 퍼셉트론이 필요하다. 단층 퍼셉트론은 비선형 영역을 분리할 수 없다.

신경망은 입력층, 출력층, 은닉층으로 구성된다.

입력 신호의 총합을 출력 신호로 변환하는 함수를 활성화 함수라고 한다.

활성화 함수의 예로 계단 함수, 시그모이드 함수, 렐루 함수가 있다. 시그모이드 함수는 딥러닝을 입문할 때 주로 쓰이지만 실무에서는 잘 쓰이지 않는다.

가중치 합을 구할 때는 행렬 곱을 활용한다.

활성화 함수를 구현할 때 회귀에서는 항등 함수를, 분류에는 소프트맥스 함수를 사용한다.

소프트 맥수 함수를 적용하면 총 합은 1이 된다. 소프트맥스 함수를 적용해도 기존의 대소는 달라지지 않는다. 따라서 현업에서는 지수함수 계산에 드는 자원 낭비를 줄이고자 출력층의 소프트맥스 함수를 생략할 수 있다.



------

실습한 코드는 [https://github.com/woduq1414/deep-learning-without-tensorflow](https://github.com/woduq1414/deep-learning-without-tensorflow) 에 있습니다.

